{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patients</th>\n",
       "      <th>Clouldy, blurry or foggy vision</th>\n",
       "      <th>Pressure in Eye?</th>\n",
       "      <th>Injury to the Eye</th>\n",
       "      <th>Excessive dryness</th>\n",
       "      <th>Red eye</th>\n",
       "      <th>Cornea increase in size</th>\n",
       "      <th>Color Identifying Problem</th>\n",
       "      <th>Double Vision</th>\n",
       "      <th>Have eye problem in family</th>\n",
       "      <th>...</th>\n",
       "      <th>Diabetics</th>\n",
       "      <th>Myopia</th>\n",
       "      <th>Trouble with glasses</th>\n",
       "      <th>Hard to see at night</th>\n",
       "      <th>Visible Whiteness</th>\n",
       "      <th>Mass pain</th>\n",
       "      <th>Vomiting</th>\n",
       "      <th>Water drops from eyes continuously</th>\n",
       "      <th>Presents of light when eye lid close</th>\n",
       "      <th>Result/Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alam</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kadir</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Farid</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rahim</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Barsha</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Patients  Clouldy, blurry or foggy vision  Pressure in Eye?  \\\n",
       "0     Alam                                0                 1   \n",
       "1    Kadir                                1                 0   \n",
       "2    Farid                                1                 0   \n",
       "3    Rahim                                0                 0   \n",
       "4   Barsha                                0                 0   \n",
       "\n",
       "   Injury to the Eye  Excessive dryness  Red eye  Cornea increase in size  \\\n",
       "0                  0                  0        0                        0   \n",
       "1                  0                  0        0                        0   \n",
       "2                  0                  0        0                        0   \n",
       "3                  0                  1        0                        0   \n",
       "4                  0                  0        1                        0   \n",
       "\n",
       "   Color Identifying Problem  Double Vision  Have eye problem in family  ...  \\\n",
       "0                          0              0                           1  ...   \n",
       "1                          1              1                           0  ...   \n",
       "2                          1              0                           1  ...   \n",
       "3                          0              0                           1  ...   \n",
       "4                          0              0                           1  ...   \n",
       "\n",
       "   Diabetics  Myopia  Trouble with glasses  Hard to see at night  \\\n",
       "0          1       0                     0                     0   \n",
       "1          1       1                     1                     0   \n",
       "2          0       1                     0                     1   \n",
       "3          1       0                     0                     0   \n",
       "4          0       0                     0                     0   \n",
       "\n",
       "   Visible Whiteness  Mass pain  Vomiting  Water drops from eyes continuously  \\\n",
       "0                  0          0         0                                   0   \n",
       "1                  0          0         0                                   0   \n",
       "2                  0          0         0                                   0   \n",
       "3                  1          0         0                                   0   \n",
       "4                  0          1         1                                   0   \n",
       "\n",
       "   Presents of light when eye lid close  Result/Outcome  \n",
       "0                                     0             101  \n",
       "1                                     0             201  \n",
       "2                                     0             201  \n",
       "3                                     0             301  \n",
       "4                                     0             401  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Docbot_Dataset.csv')\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(563, 21)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ei khane data ke 2 way te devide korbo\n",
    "# input multiple hbe but output sudu ekta tai hbe\n",
    "\n",
    "real_x = data.iloc[:,1:20].values\n",
    "real_y = data.iloc[:,20].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 1, 0, ..., 1, 1, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([101, 201, 201, 301, 401, 401, 201, 501, 301, 401, 301, 301, 301,\n",
       "       301, 301, 301, 301, 301, 301, 301, 301, 301, 301, 301, 301, 101,\n",
       "       101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
       "       101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
       "       101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
       "       101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
       "       101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
       "       101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
       "       101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
       "       101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
       "       101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
       "       101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
       "       101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
       "       101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
       "       101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 301,\n",
       "       301, 301, 301, 301, 301, 301, 301, 301, 301, 301, 301, 301, 301,\n",
       "       301, 301, 301, 301, 301, 301, 301, 301, 301, 301, 201, 201, 201,\n",
       "       201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201,\n",
       "       201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201,\n",
       "       201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201,\n",
       "       201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201,\n",
       "       201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201,\n",
       "       201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201,\n",
       "       201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201,\n",
       "       201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201,\n",
       "       201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201,\n",
       "       201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201,\n",
       "       201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201,\n",
       "       201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201,\n",
       "       201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201,\n",
       "       201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201,\n",
       "       201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201,\n",
       "       201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201,\n",
       "       201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201, 201,\n",
       "       201, 201, 201, 201, 201, 201, 201, 201, 201, 501, 501, 501, 501,\n",
       "       501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501,\n",
       "       501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501,\n",
       "       501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501,\n",
       "       501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501, 501,\n",
       "       401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401,\n",
       "       401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401,\n",
       "       401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401,\n",
       "       401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401, 401,\n",
       "       401, 401, 401, 401], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supervised learning e ... dataset -->> traing ar testing dataset e divided kora hoy\n",
    "# training er data ... 70-80 % rakte hbe er theke besi ora kom hote parbe na \n",
    "# testing er data ... baki % e rakbo\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split  # divide korar jonno library\n",
    "training_x,testing_x,training_y,testing_y = train_test_split(real_x,real_y,test_size = 0.2,random_state = 0)  # data set split kortesi\n",
    "            # randodm_state = 0 na dile ans ekbar ekta asbo \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 1, 1],\n",
       "       [1, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 1, 0],\n",
       "       ...,\n",
       "       [1, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 1, 0],\n",
       "       [0, 1, 0, ..., 0, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 1, 1, ..., 0, 1, 0],\n",
       "       ...,\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression  # Model built er jonno library\n",
    "MLR = LinearRegression() # ei cls er object ---> Lin\n",
    "MLR.fit(training_x,training_y) # ei khane ei Model train kora hoise # Model ke fit kora hoise  --> fit = cls e 2 ta argument nei ei gula Training er sate related\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([501, 201, 101, 501, 201, 201, 401, 201, 201, 401, 301, 201, 101,\n",
       "       101, 101, 201, 101, 201, 401, 201, 201, 201, 101, 101, 101, 201,\n",
       "       101, 201, 101, 501, 201, 301, 101, 201, 401, 401, 501, 201, 401,\n",
       "       101, 201, 501, 501, 201, 401, 201, 201, 201, 201, 501, 301, 201,\n",
       "       201, 201, 201, 301, 201, 501, 401, 501, 201, 101, 201, 401, 101,\n",
       "       501, 401, 501, 201, 101, 201, 101, 101, 501, 301, 101, 101, 101,\n",
       "       501, 201, 101, 401, 201, 101, 201, 201, 201, 101, 201, 201, 301,\n",
       "       301, 101, 501, 401, 201, 501, 201, 201, 201, 401, 201, 101, 101,\n",
       "       201, 201, 201, 401, 201, 301, 201, 101, 101], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_y # real "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([406.60215394, 188.37033784, 194.18747349, 409.05525436,\n",
       "       183.47787892, 175.56645382, 291.89637032, 201.10967378,\n",
       "       238.71004522, 349.47970811, 294.44581394, 187.65399252,\n",
       "       171.19993073, 109.45168786,  95.98479808, 212.51168845,\n",
       "       104.55922893, 227.12509101, 468.001891  , 227.84143634,\n",
       "       179.74256742, 227.58780612,  84.5827834 , 184.95586871,\n",
       "       125.20212102, 233.8175863 , 164.97015055, 183.47787892,\n",
       "       102.21457826, 475.38896008, 199.77235252, 338.45746642,\n",
       "        84.5827834 , 228.27333014, 469.1044543 , 322.77934073,\n",
       "       482.33333231, 182.32963979, 411.9017616 , 144.33653108,\n",
       "       234.35099209, 439.50152519, 270.23569478, 256.87524587,\n",
       "       423.30377628, 183.47787892, 190.24106489, 239.24345101,\n",
       "       190.24106489, 304.44805342, 300.29752433, 244.75688587,\n",
       "       183.47787892, 188.37033784, 239.99082437, 276.2587505 ,\n",
       "       194.8798936 , 205.58948817, 343.24992793, 546.54808464,\n",
       "       224.09721654, 145.17856656, 183.47787892, 329.55594294,\n",
       "        89.47524233, 401.8932848 , 443.03827871, 612.2187846 ,\n",
       "       183.47787892, 142.83391588, 207.87285975, 104.55922893,\n",
       "       125.20212102, 383.5120344 , 268.80431927, 155.73854576,\n",
       "        84.5827834 ,  84.5827834 , 421.86973033, 183.47787892,\n",
       "        84.5827834 , 471.44910498, 183.47787892,  84.5827834 ,\n",
       "       442.33966729, 183.47787892, 241.7290114 , 102.21457826,\n",
       "       194.8798936 , 199.0560072 , 322.82177811, 305.84782862,\n",
       "       102.21457826, 349.40225254, 353.05525645, 188.37033784,\n",
       "       539.31097503, 224.09721654, 207.87285975, 222.35902952,\n",
       "       279.51997993, 175.56645382,  95.98479808, 130.09457995,\n",
       "       190.24106489, 183.47787892, 180.07547636, 455.8709767 ,\n",
       "       183.47787892, 364.45755105, 188.37033784, 149.22899001,\n",
       "       125.20212102])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pred_y = MLR.predict(testing_x)\n",
    "Pred_y  # prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# wrong But for test\n",
    "\n",
    "Final_Accurcy_test = (Pred_y / testing_y)*100\n",
    "Final_Accurcy_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-46.7925757 , -59.75374768, -40.61933762,  15.63568831,\n",
       "        53.03778762, 143.0596047 ,  -6.76318597,  -4.1761136 ,\n",
       "        -4.89245892, -11.40201468, -17.63179486, -68.98535247,\n",
       "        27.98257846,   7.9114251 ,  14.97784295,  79.13758975,\n",
       "        53.95404623, -19.97644553, 124.67835431])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eita formula diya korar way but ota ektu kotin tai eta ektu dekai se # aage simple eay te kora ase\n",
    "\n",
    "MLR.coef_   # Multiple input tai multiple asce  # Coeficient er value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "307.8439351649781"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLR.intercept_   # Intercept er value # Output ektai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as sm # need for backword elimination remove korbar jonno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 0, ..., 0, 0, 0],\n",
       "       [1, 1, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 0, 1, ..., 1, 1, 0],\n",
       "       [1, 0, 0, ..., 1, 0, 0],\n",
       "       [1, 0, 0, ..., 1, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_x = np.append(arr=np.ones((563,1)).astype(int),values=real_x,axis=1)  # x0 = 1 kora hoise  # Shift + tab --> dekbo\n",
    "real_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 1., ..., 0., 0., 0.],\n",
       "       [1., 1., 0., ..., 0., 0., 0.],\n",
       "       [1., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 1., ..., 1., 1., 0.],\n",
       "       [1., 0., 0., ..., 1., 0., 0.],\n",
       "       [1., 0., 0., ..., 1., 0., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_opt = np.array(real_x[:, [0, 1, 2, 3, 4, 5,6,7,8,9,10,11,12,13,14,15,16,17,18,19]], dtype=float)  # dtype=float ---> eta na dile pore kaje vul asbe\n",
    "X_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "regressor_OLS = sm.OLS(endog = real_y, exog = X_opt).fit()\n",
    "\n",
    "                # fit() -- Model Train Korsi\n",
    "                # OLS = Ordinary List Square Method\n",
    "                # endog = Output Value\n",
    "                # exog = Input Value oR Optimize Value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.850</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.844</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   161.5</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 05 Oct 2020</td> <th>  Prob (F-statistic):</th> <td>4.72e-209</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>12:49:39</td>     <th>  Log-Likelihood:    </th> <td> -2994.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   563</td>      <th>  AIC:               </th> <td>   6030.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   543</td>      <th>  BIC:               </th> <td>   6116.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    19</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>  320.1225</td> <td>    9.847</td> <td>   32.510</td> <td> 0.000</td> <td>  300.780</td> <td>  339.465</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>  -54.7240</td> <td>    9.078</td> <td>   -6.028</td> <td> 0.000</td> <td>  -72.555</td> <td>  -36.893</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>  -64.9896</td> <td>    7.742</td> <td>   -8.395</td> <td> 0.000</td> <td>  -80.197</td> <td>  -49.782</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>  -41.2093</td> <td>    5.779</td> <td>   -7.131</td> <td> 0.000</td> <td>  -52.561</td> <td>  -29.858</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    9.6418</td> <td>   12.504</td> <td>    0.771</td> <td> 0.441</td> <td>  -14.920</td> <td>   34.204</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>   52.8865</td> <td>   10.414</td> <td>    5.078</td> <td> 0.000</td> <td>   32.430</td> <td>   73.343</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>  134.9551</td> <td>   11.085</td> <td>   12.175</td> <td> 0.000</td> <td>  113.181</td> <td>  156.729</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>  -12.9495</td> <td>    7.720</td> <td>   -1.677</td> <td> 0.094</td> <td>  -28.114</td> <td>    2.215</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>   -6.8479</td> <td>    7.467</td> <td>   -0.917</td> <td> 0.360</td> <td>  -21.516</td> <td>    7.820</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>   -8.5613</td> <td>    5.146</td> <td>   -1.664</td> <td> 0.097</td> <td>  -18.669</td> <td>    1.547</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>  -12.7859</td> <td>    5.110</td> <td>   -2.502</td> <td> 0.013</td> <td>  -22.824</td> <td>   -2.747</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>  -12.9603</td> <td>    5.089</td> <td>   -2.547</td> <td> 0.011</td> <td>  -22.958</td> <td>   -2.963</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>  -80.8049</td> <td>    7.508</td> <td>  -10.763</td> <td> 0.000</td> <td>  -95.553</td> <td>  -66.057</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>   30.0920</td> <td>   14.647</td> <td>    2.054</td> <td> 0.040</td> <td>    1.320</td> <td>   58.864</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>   12.5677</td> <td>    7.441</td> <td>    1.689</td> <td> 0.092</td> <td>   -2.049</td> <td>   27.184</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>    4.6527</td> <td>   12.301</td> <td>    0.378</td> <td> 0.705</td> <td>  -19.511</td> <td>   28.816</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td>   59.4608</td> <td>   10.088</td> <td>    5.894</td> <td> 0.000</td> <td>   39.644</td> <td>   79.277</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td>   53.8235</td> <td>    9.959</td> <td>    5.405</td> <td> 0.000</td> <td>   34.261</td> <td>   73.386</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td>  -14.1199</td> <td>    7.176</td> <td>   -1.968</td> <td> 0.050</td> <td>  -28.216</td> <td>   -0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td>  118.0599</td> <td>   11.008</td> <td>   10.725</td> <td> 0.000</td> <td>   96.437</td> <td>  139.683</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>146.851</td> <th>  Durbin-Watson:     </th> <td>   0.972</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 911.189</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.991</td>  <th>  Prob(JB):          </th> <td>1.37e-198</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 8.909</td>  <th>  Cond. No.          </th> <td>    15.5</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.850\n",
       "Model:                            OLS   Adj. R-squared:                  0.844\n",
       "Method:                 Least Squares   F-statistic:                     161.5\n",
       "Date:                Mon, 05 Oct 2020   Prob (F-statistic):          4.72e-209\n",
       "Time:                        12:49:39   Log-Likelihood:                -2994.8\n",
       "No. Observations:                 563   AIC:                             6030.\n",
       "Df Residuals:                     543   BIC:                             6116.\n",
       "Df Model:                          19                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const        320.1225      9.847     32.510      0.000     300.780     339.465\n",
       "x1           -54.7240      9.078     -6.028      0.000     -72.555     -36.893\n",
       "x2           -64.9896      7.742     -8.395      0.000     -80.197     -49.782\n",
       "x3           -41.2093      5.779     -7.131      0.000     -52.561     -29.858\n",
       "x4             9.6418     12.504      0.771      0.441     -14.920      34.204\n",
       "x5            52.8865     10.414      5.078      0.000      32.430      73.343\n",
       "x6           134.9551     11.085     12.175      0.000     113.181     156.729\n",
       "x7           -12.9495      7.720     -1.677      0.094     -28.114       2.215\n",
       "x8            -6.8479      7.467     -0.917      0.360     -21.516       7.820\n",
       "x9            -8.5613      5.146     -1.664      0.097     -18.669       1.547\n",
       "x10          -12.7859      5.110     -2.502      0.013     -22.824      -2.747\n",
       "x11          -12.9603      5.089     -2.547      0.011     -22.958      -2.963\n",
       "x12          -80.8049      7.508    -10.763      0.000     -95.553     -66.057\n",
       "x13           30.0920     14.647      2.054      0.040       1.320      58.864\n",
       "x14           12.5677      7.441      1.689      0.092      -2.049      27.184\n",
       "x15            4.6527     12.301      0.378      0.705     -19.511      28.816\n",
       "x16           59.4608     10.088      5.894      0.000      39.644      79.277\n",
       "x17           53.8235      9.959      5.405      0.000      34.261      73.386\n",
       "x18          -14.1199      7.176     -1.968      0.050     -28.216      -0.023\n",
       "x19          118.0599     11.008     10.725      0.000      96.437     139.683\n",
       "==============================================================================\n",
       "Omnibus:                      146.851   Durbin-Watson:                   0.972\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              911.189\n",
       "Skew:                           0.991   Prob(JB):                    1.37e-198\n",
       "Kurtosis:                       8.909   Cond. No.                         15.5\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor_OLS.summary()   # Sob gular Summary aisa gase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.850</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.845</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   170.7</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 05 Oct 2020</td> <th>  Prob (F-statistic):</th> <td>3.83e-210</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>12:49:40</td>     <th>  Log-Likelihood:    </th> <td> -2994.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   563</td>      <th>  AIC:               </th> <td>   6028.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   544</td>      <th>  BIC:               </th> <td>   6110.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    18</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>  321.3484</td> <td>    9.291</td> <td>   34.587</td> <td> 0.000</td> <td>  303.098</td> <td>  339.599</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>  -55.3539</td> <td>    8.916</td> <td>   -6.208</td> <td> 0.000</td> <td>  -72.869</td> <td>  -37.839</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>  -65.1290</td> <td>    7.727</td> <td>   -8.429</td> <td> 0.000</td> <td>  -80.307</td> <td>  -49.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>  -41.4445</td> <td>    5.741</td> <td>   -7.219</td> <td> 0.000</td> <td>  -52.721</td> <td>  -30.168</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   11.2257</td> <td>   11.773</td> <td>    0.954</td> <td> 0.341</td> <td>  -11.899</td> <td>   34.351</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>   52.5631</td> <td>   10.371</td> <td>    5.068</td> <td> 0.000</td> <td>   32.192</td> <td>   72.935</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>  134.4207</td> <td>   10.986</td> <td>   12.236</td> <td> 0.000</td> <td>  112.841</td> <td>  156.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>  -13.2114</td> <td>    7.683</td> <td>   -1.720</td> <td> 0.086</td> <td>  -28.303</td> <td>    1.880</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>   -7.0871</td> <td>    7.434</td> <td>   -0.953</td> <td> 0.341</td> <td>  -21.691</td> <td>    7.516</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>   -8.6138</td> <td>    5.140</td> <td>   -1.676</td> <td> 0.094</td> <td>  -18.710</td> <td>    1.482</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>  -12.7742</td> <td>    5.106</td> <td>   -2.502</td> <td> 0.013</td> <td>  -22.804</td> <td>   -2.744</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>  -13.0490</td> <td>    5.080</td> <td>   -2.569</td> <td> 0.010</td> <td>  -23.028</td> <td>   -3.070</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>  -81.2021</td> <td>    7.428</td> <td>  -10.931</td> <td> 0.000</td> <td>  -95.794</td> <td>  -66.610</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>   30.3319</td> <td>   14.622</td> <td>    2.074</td> <td> 0.039</td> <td>    1.609</td> <td>   59.055</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>   12.6903</td> <td>    7.428</td> <td>    1.708</td> <td> 0.088</td> <td>   -1.901</td> <td>   27.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>   58.8923</td> <td>    9.968</td> <td>    5.908</td> <td> 0.000</td> <td>   39.313</td> <td>   78.472</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td>   53.3135</td> <td>    9.860</td> <td>    5.407</td> <td> 0.000</td> <td>   33.946</td> <td>   72.681</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td>  -14.5662</td> <td>    7.073</td> <td>   -2.059</td> <td> 0.040</td> <td>  -28.460</td> <td>   -0.673</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td>  117.5309</td> <td>   10.910</td> <td>   10.773</td> <td> 0.000</td> <td>   96.100</td> <td>  138.962</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>145.071</td> <th>  Durbin-Watson:     </th> <td>   0.979</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 897.478</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.977</td>  <th>  Prob(JB):          </th> <td>1.30e-195</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 8.868</td>  <th>  Cond. No.          </th> <td>    15.2</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.850\n",
       "Model:                            OLS   Adj. R-squared:                  0.845\n",
       "Method:                 Least Squares   F-statistic:                     170.7\n",
       "Date:                Mon, 05 Oct 2020   Prob (F-statistic):          3.83e-210\n",
       "Time:                        12:49:40   Log-Likelihood:                -2994.9\n",
       "No. Observations:                 563   AIC:                             6028.\n",
       "Df Residuals:                     544   BIC:                             6110.\n",
       "Df Model:                          18                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const        321.3484      9.291     34.587      0.000     303.098     339.599\n",
       "x1           -55.3539      8.916     -6.208      0.000     -72.869     -37.839\n",
       "x2           -65.1290      7.727     -8.429      0.000     -80.307     -49.951\n",
       "x3           -41.4445      5.741     -7.219      0.000     -52.721     -30.168\n",
       "x4            11.2257     11.773      0.954      0.341     -11.899      34.351\n",
       "x5            52.5631     10.371      5.068      0.000      32.192      72.935\n",
       "x6           134.4207     10.986     12.236      0.000     112.841     156.000\n",
       "x7           -13.2114      7.683     -1.720      0.086     -28.303       1.880\n",
       "x8            -7.0871      7.434     -0.953      0.341     -21.691       7.516\n",
       "x9            -8.6138      5.140     -1.676      0.094     -18.710       1.482\n",
       "x10          -12.7742      5.106     -2.502      0.013     -22.804      -2.744\n",
       "x11          -13.0490      5.080     -2.569      0.010     -23.028      -3.070\n",
       "x12          -81.2021      7.428    -10.931      0.000     -95.794     -66.610\n",
       "x13           30.3319     14.622      2.074      0.039       1.609      59.055\n",
       "x14           12.6903      7.428      1.708      0.088      -1.901      27.282\n",
       "x15           58.8923      9.968      5.908      0.000      39.313      78.472\n",
       "x16           53.3135      9.860      5.407      0.000      33.946      72.681\n",
       "x17          -14.5662      7.073     -2.059      0.040     -28.460      -0.673\n",
       "x18          117.5309     10.910     10.773      0.000      96.100     138.962\n",
       "==============================================================================\n",
       "Omnibus:                      145.071   Durbin-Watson:                   0.979\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              897.478\n",
       "Skew:                           0.977   Prob(JB):                    1.30e-195\n",
       "Kurtosis:                       8.868   Cond. No.                         15.2\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_opt = np.array(real_x[:, [0, 1, 2, 3, 4, 5,6,7,8,9,10,11,12,13,14,16,17,18,19]], dtype=float) # 15 remove bcoz SL=0.5\n",
    "regressor_OLS = sm.OLS(endog = real_y, exog = X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tar 15 no Column bad diiya abr M.L.R Apply korle valo prediction pabo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ekhon jei gula paisi ei gulai Optimize result (x1 - x19) , P>|t| = 0.000 ,Here SL = 0.5 (Consider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ei Algorithm use hoy Most Significant Indipendent variable ke Find out korar jonno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('Train Score: ', regressor.score(x_train, y_train))  \n",
    "#print('Test Score: ', regressor.score(x_test, y_test))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
